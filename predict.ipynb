{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(city):\n",
    "    # Get today's date and the date 7 days ago\n",
    "    today = datetime.today()\n",
    "    seven_days_ago = today - timedelta(days=6)\n",
    "   \n",
    "    # Format dates to strings\n",
    "    today_str = today.strftime('%Y-%m-%d')\n",
    "    seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d')\n",
    " \n",
    "    # API Connection to RapidAPI Weather API\n",
    "    conn = http.client.HTTPSConnection(\"weatherapi-com.p.rapidapi.com\")\n",
    " \n",
    "    headers = {\n",
    "           'x-rapidapi-key': \"1189d1cbfcmshff6e7d2c8e7e466p1490a7jsn53d09429c10e\",\n",
    "    'x-rapidapi-host': \"weatherapi-com.p.rapidapi.com\"\n",
    "    }\n",
    " \n",
    "    # API URL to fetch historical weather data\n",
    "    url = f\"/history.json?q={city}&lang=en&dt={seven_days_ago_str}&end_dt={today_str}\"\n",
    " \n",
    "    # Make the API request\n",
    "    conn.request(\"GET\", url, headers=headers)\n",
    " \n",
    "    # Get the response\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "   \n",
    " \n",
    "    # Parse the JSON response\n",
    " \n",
    "    weather_data = json.loads(data.decode(\"utf-8\"))\n",
    "   \n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def convert_to_csv(weather_data, city):\n",
    "    header = [\"Date\", \"AvgTemp\", \"Humidity\", \"WindSpeed\", \"Precipitation\", \"Condition\"]\n",
    "    rows = []\n",
    " \n",
    "    # Loop through the forecast data and add each day's weather information\n",
    "    for day in weather_data['forecast']['forecastday']:\n",
    "        rows.append([\n",
    "            day['date'],  # Date\n",
    "            day['day']['avgtemp_c'],  # Average Temperature (Celsius)\n",
    "            day['day']['avghumidity'],  # Average Humidity\n",
    "            day['day']['maxwind_kph'],  # Max Wind Speed (kph)\n",
    "            day['day']['totalprecip_mm'],  # Precipitation (mm)\n",
    "            day['day']['condition']['text']  # Weather Condition (text)\n",
    "        ])\n",
    "   \n",
    "    # Write the data to a CSV file using the csv module\n",
    "    csv_filename = f\"{city}_weather_data.csv\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(csv_filename):\n",
    "        existing_df = pd.read_csv(csv_filename)\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=header)\n",
    "    \n",
    "    # Convert new data into a DataFrame\n",
    "    new_df = pd.DataFrame(rows, columns=header)\n",
    "    \n",
    "    # Merge old and new data, removing duplicates\n",
    "    updated_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=[\"Date\"], keep=\"last\")\n",
    "    \n",
    "    # Save updated data\n",
    "    updated_df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"CSV file '{csv_filename}' updated successfully.\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Chennai_weather_data.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "city='Chennai'\n",
    "weatherdata = fetch_weather_data(city)\n",
    "convert_to_csv(weatherdata,city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(csv_filename):\n",
    "     # Load the CSV data into a DataFrame\n",
    "    df = pd.read_csv(csv_filename)\n",
    " \n",
    "    # Ensure the 'Date' column is in datetime format (if you need to keep it)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    " \n",
    "    # Drop the 'Date' column as it's not useful for prediction\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    " \n",
    "    # One-hot encode the 'Condition' column (convert categorical to numeric)\n",
    "    encoder = OneHotEncoder(sparse_output=False,handle_unknown='ignore')\n",
    "    condition_encoded = encoder.fit_transform(df[['Condition']])\n",
    "    condition_df = pd.DataFrame(condition_encoded, columns=encoder.get_feature_names_out(['Condition']))\n",
    " \n",
    "    # Concatenate the one-hot encoded columns back into the original dataframe (without 'Condition' column)\n",
    "    df = pd.concat([df.drop(columns=['Condition']), condition_df], axis=1)\n",
    " \n",
    "    # Handle missing values (simple imputation strategy)\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    \n",
    "    # Feature columns (excluding the target column 'AvgTemp')\n",
    "    X = df.drop(columns=[\"AvgTemp\"])\n",
    "    print(X)\n",
    " \n",
    "    # Target column (assuming you're predicting 'AvgTemp')\n",
    "    y = df[\"AvgTemp\"]\n",
    "    X = X.values\n",
    " \n",
    "    # Normalize the features (optional)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    " \n",
    "    print(\"Shape of X_scaled:\", X_scaled.shape)\n",
    "    return X_scaled, y,scaler,encoder\n",
    " \n",
    " \n",
    "def split_data(X, y):\n",
    "    # Split the data into training and testing sets (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print('x train in split',X_train)\n",
    "    return X_train, X_test, y_train, y_test\n",
    " \n",
    " \n",
    " \n",
    "def train_model(X_train, y_train):\n",
    "    # Initialize the XGBoost model\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
    "    print(\"Shape of X_train:\", X_train.shape)\n",
    "   \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "    return model\n",
    " \n",
    " \n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    " \n",
    "    # Evaluate the model using Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    " \n",
    "    # You can also print predicted vs actual values if needed\n",
    "    comparison = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "    print(comparison.head())\n",
    " \n",
    " \n",
    "def predict_next_day_temperature(model, input_data):\n",
    "    # Make a prediction for the next day's temperature\n",
    "    predicted_temp = model.predict(input_data)\n",
    "    print(f\"Predicted temperature for next day: {predicted_temp[0]:.2f}°C\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Humidity  WindSpeed  Precipitation  Condition_Light rain shower  \\\n",
      "0      66.0       19.4           0.00                          0.0   \n",
      "1      66.0       21.6           0.00                          0.0   \n",
      "2      63.0       19.8           0.00                          0.0   \n",
      "3      65.0       20.2           0.00                          0.0   \n",
      "4      78.0       23.8           1.68                          1.0   \n",
      "5      74.0       20.2           0.19                          0.0   \n",
      "6      74.0       19.4           0.00                          0.0   \n",
      "\n",
      "   Condition_Partly cloudy  Condition_Sunny  \n",
      "0                      0.0              1.0  \n",
      "1                      0.0              1.0  \n",
      "2                      0.0              1.0  \n",
      "3                      0.0              1.0  \n",
      "4                      0.0              0.0  \n",
      "5                      1.0              0.0  \n",
      "6                      0.0              1.0  \n",
      "Shape of X_scaled: (7, 6)\n",
      "x train in split [[ 0.85584751 -0.29204775 -0.13288808 -0.40824829  2.44948974 -1.58113883]\n",
      " [-1.20353556 -0.56462565 -0.4601865  -0.40824829 -0.40824829  0.63245553]\n",
      " [ 1.60471409  2.16115334  2.43382059  2.44948974 -0.40824829 -1.58113883]\n",
      " [-0.82910228 -0.29204775 -0.4601865  -0.40824829 -0.40824829  0.63245553]\n",
      " [ 0.85584751 -0.83720355 -0.4601865  -0.40824829 -0.40824829  0.63245553]]\n",
      "xtrain [[ 0.85584751 -0.29204775 -0.13288808 -0.40824829  2.44948974 -1.58113883]\n",
      " [-1.20353556 -0.56462565 -0.4601865  -0.40824829 -0.40824829  0.63245553]\n",
      " [ 1.60471409  2.16115334  2.43382059  2.44948974 -0.40824829 -1.58113883]\n",
      " [-0.82910228 -0.29204775 -0.4601865  -0.40824829 -0.40824829  0.63245553]\n",
      " [ 0.85584751 -0.83720355 -0.4601865  -0.40824829 -0.40824829  0.63245553]]\n",
      "Shape of X_train: (5, 6)\n",
      "Mean Absolute Error: 0.16\n",
      "   Actual  Predicted\n",
      "0    26.7  26.821018\n",
      "1    26.4  26.600048\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 6, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m evaluate_model(model, X_test, y_test)\n\u001b[32m      6\u001b[39m input_data = [[\u001b[32m26.4\u001b[39m, \u001b[32m81\u001b[39m, \u001b[32m22\u001b[39m, \u001b[32m0.05\u001b[39m, \u001b[32m6\u001b[39m]]  \u001b[38;5;66;03m# Example input data for the model (replace with your own)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mpredict_next_day_temperature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mpredict_next_day_temperature\u001b[39m\u001b[34m(model, input_data)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_next_day_temperature\u001b[39m(model, input_data):\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Make a prediction for the next day's temperature\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     predicted_temp = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted temperature for next day: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_temp[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m°C\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gebruiker FOM011\\Desktop\\weather_app\\flask_env\\Lib\\site-packages\\xgboost\\sklearn.py:1248\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1257\u001b[39m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gebruiker FOM011\\Desktop\\weather_app\\flask_env\\Lib\\site-packages\\xgboost\\core.py:2524\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2520\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2521\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2522\u001b[39m         )\n\u001b[32m   2523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) != \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_features() != data.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2525\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2526\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         )\n\u001b[32m   2529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[32m   2530\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[31mValueError\u001b[39m: Feature shape mismatch, expected: 6, got 5"
     ]
    }
   ],
   "source": [
    "X_scaled, y,scaler,encoder = preprocess_data(f\"{city}_weather_data.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "print('xtrain',X_train)\n",
    "model = train_model(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)\n",
    "input_data = [[26.4, 81, 22, 0.05, 6]]  # Example input data for the model (replace with your own)\n",
    "predict_next_day_temperature(model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Example of usage\u001b[39;00m\n\u001b[32m     52\u001b[39m \n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Load the data and preprocess it, get the encoder and scaler\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m X_scaled, y, scaler, encoder = \u001b[43mpreprocess_data\u001b[49m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_weather_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Assume the model is already trained, and we have the last known data point (e.g., the last row from the dataset)\u001b[39;00m\n\u001b[32m     57\u001b[39m last_known_data = X_scaled[-\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# Use the last row as the input for prediction\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def predict_next_7_days(model, last_known_data, scaler, encoder, days=7):\n",
    "    predictions = []\n",
    " \n",
    "    # Get the last known input data (scaled and encoded)\n",
    "    current_input = last_known_data\n",
    "    print('last known dats is',last_known_data)\n",
    "    last_known_humidity = current_input[0, 1]  # Assuming 2nd column is Humidity\n",
    "    last_known_windspeed = current_input[0, 2]  # Assuming 3rd column is WindSpeed\n",
    "    last_known_precipitation = current_input[0, 3]  # Assuming 4th column is Precipitation\n",
    "    last_known_condition_encoded = current_input[0, 4]\n",
    "    # last_known_condition_encoded = current_input[0, -len(encoder.categories_[0]):]  # The encoded \"Condition\" features from the last data point\n",
    "   \n",
    "    # Predict for 7 days\n",
    "    for day in range(days):\n",
    "        # Use the model to predict the next day's weather\n",
    "        prediction = model.predict(current_input)\n",
    " \n",
    "        # Store the prediction (assuming a single value like AvgTemp)\n",
    "        predictions.append(prediction[0])  \n",
    "       \n",
    "        # Simulate small random changes in weather features\n",
    "        next_day_humidity = last_known_humidity + np.random.normal(0, 10)  \n",
    "        next_day_windspeed = last_known_windspeed + np.random.normal(0, 2)  \n",
    "        next_day_precipitation = last_known_precipitation + np.random.normal(0, 0.1)  \n",
    " \n",
    "        possible_conditions = ['Clear', 'Cloudy', 'Rainy', 'Windy', 'Snow']\n",
    "        random_condition = random.choice(possible_conditions)\n",
    "       \n",
    "        # Get the one-hot encoded vector for the chosen condition\n",
    "        next_day_condition = encoder.transform([[random_condition]])  # Encoding the new condition\n",
    "        next_day_condition_feature = next_day_condition[0, 0]\n",
    "        # Prepare the new data point (in the same order as the features used for training)\n",
    "        # Now, the new data point should have exactly 4 numerical features + 1 encoded condition feature\n",
    "        new_data_point = np.array([[prediction[0], next_day_humidity, next_day_windspeed, next_day_precipitation]])\n",
    " \n",
    "        # Concatenate the selected condition feature (just one feature) to the new data point\n",
    "        new_data_point = np.concatenate([new_data_point, np.array([[next_day_condition_feature]])], axis=1)\n",
    " \n",
    "        # Ensure the new data point has exactly 5 features (check before scaling)\n",
    "        # print(f\"Shape of new_data_point before scaling: {new_data_point.shape}\")  # Debugging print\n",
    "        assert new_data_point.shape[1] == 5, f\"Expected 5 features, got {new_data_point.shape[1]}\"\n",
    " \n",
    "        # Scale the entire new data point (numerical features + encoded condition)\n",
    "        current_input = scaler.transform(new_data_point)  # The input now has the correct number of features (5)\n",
    " \n",
    "    return predictions\n",
    " \n",
    " \n",
    "# Example of usage\n",
    " \n",
    "# Load the data and preprocess it, get the encoder and scaler\n",
    "X_scaled, y, scaler, encoder = preprocess_data(f\"{city}_weather_data.csv\")\n",
    " \n",
    "# Assume the model is already trained, and we have the last known data point (e.g., the last row from the dataset)\n",
    "last_known_data = X_scaled[-1:]  # Use the last row as the input for prediction\n",
    " \n",
    "# Make predictions for the next 7 days\n",
    "predictions = predict_next_7_days(model, last_known_data, scaler, encoder, days=7)\n",
    " \n",
    "# Print or display the predictions for the next 7 days\n",
    "for i, prediction in enumerate(predictions, 1):\n",
    "    print(f\"Day {i}: Predicted AvgTemp = {prediction:.2f}°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
